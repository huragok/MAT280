{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import cmath\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.linalg import svd\n",
    "from numpy.random import uniform\n",
    "from scipy import io\n",
    "from scipy.linalg import eigh\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from mpl_toolkits.axes_grid1.inset_locator import mark_inset\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib qt\n",
    "sns.set()\n",
    "axis_font = {'size':'16'}\n",
    "mpl.rcParams['xtick.labelsize'] = 16\n",
    "mpl.rcParams['ytick.labelsize'] = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data files. The 8 non-empty strings are mapped to the unit circle in the complex plane separated by 45 degrees and '--' are mapped to the origin. In this way we hope that the 'pure' patters are separated by the 'hybrid' patters, and '--' is not biased towards any non-empty pattern. Each column of $X$ are shifted to have zero mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = io.loadmat('genomedata.mat')\n",
    "map_gen = {'AA': complex(0.0, 1.0),\n",
    "           'CC': complex(-1.0, 0.0),\n",
    "           'GG': complex(1.0, 0.0),\n",
    "           'TT': complex(0.0, -1.0),\n",
    "           'AG': complex(1.0 / math.sqrt(2), 1.0 / math.sqrt(2)),\n",
    "           'AC': complex(-1.0 / math.sqrt(2), 1.0 / math.sqrt(2)),\n",
    "           'TC': complex(-1.0 / math.sqrt(2), -1.0 / math.sqrt(2)),\n",
    "           'TG': complex(1.0 / math.sqrt(2), -1.0 / math.sqrt(2)), \n",
    "           '--': complex(0.0, 0.0)}\n",
    "\n",
    "X_raw = [[string.strip() for string in row[0][0].strip().split('\\t')] for row in data['X']]\n",
    "X = np.array([[map_gen[string] for string in row] for row in X_raw])\n",
    "n, p = X.shape\n",
    "X = X - np.mean(X, axis=0) * np.ones(p)\n",
    "\n",
    "random_state = 8 # The random state used by the KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select the parameter $k$ of the k-means properly we define the following function to evaluate the gap statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The function to evaluate the gap statistic for k-means with different number of clusters\n",
    "def get_gapstat(X, k_range=np.arange(1, 9), n_sample=20, random_state=8):\n",
    "    n, p = X.shape\n",
    "    \n",
    "    X_ref = np.empty((n, p, n_sample), dtype='float64')\n",
    "    for col in range(p):\n",
    "        X_ref[:, col, :] = uniform(low=X[:, col].min(), high=X[:, col].max(), size=(n, n_sample))\n",
    "    \n",
    "    gapstat = np.empty((n_sample, len(k_range)), dtype='float64')\n",
    "    for i_k, k in enumerate(k_range):\n",
    "        km = KMeans(n_clusters=k, random_state=random_state)\n",
    "        \n",
    "        # The inertia of the actual data\n",
    "        km.fit(X)\n",
    "        w = km.inertia_\n",
    "        \n",
    "        # The inertia of the reference data\n",
    "        w_ref = np.empty(n_sample, dtype='float64')\n",
    "        for i_sample in range(n_sample):\n",
    "            km.fit(X_ref[:, :, i_sample])\n",
    "            w_ref[i_sample] = km.inertia_\n",
    "        \n",
    "        gapstat[:, i_k] = np.log(w_ref) - np.log(w)\n",
    "        \n",
    "    return gapstat\n",
    "\n",
    "k_range = np.arange(1, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 1: Dimension reduction by PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_pca = 2 # For PCA we reduce the dimension of X down to 3\n",
    "k_pca = 2 # The expected number of clusters for PCA\n",
    "\n",
    "_, s_pca, V_pca = svd(X) # svd of X. Note that this is different from matlab in that X = U diag(s) V.\n",
    "V_pca = np.conjugate(V_pca.T)\n",
    "\n",
    "X_pca_complex = np.dot(X, V_pca[:, 0 : d_pca]) # Reduce the dimension of X by linear projection, a complex matrix\n",
    "\n",
    "# Since KMeans does not seem to support complex value, expand the space to 2*d_pca dim\n",
    "X_pca = np.empty((n, 2 * d_pca), dtype=\"float64\") \n",
    "X_pca[:, 0::2] = X_pca_complex.real\n",
    "X_pca[:, 1::2] = X_pca_complex.imag\n",
    "\n",
    "label_pca = KMeans(n_clusters=2, random_state=random_state).fit_predict(X_pca)\n",
    "gap_pca = get_gapstat(X_pca, k_range=k_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the distribution of the singular value, and the scattermatrix plot of the reduced dimension data and the gap statistic for different $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Distribution of the sinular values\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "axins = inset_axes(ax, 2, 3, loc=1) # zoom-factor: 2.5, location: upper-left\n",
    "\n",
    "ax.semilogy(np.arange(p), s_pca, linewidth=2)\n",
    "ax.grid(True)\n",
    "ax.set_xlabel('dimension', **axis_font)\n",
    "ax.set_ylabel('singular value', **axis_font)\n",
    "\n",
    "axins.semilogy(np.arange(p), s_pca, linewidth=2)\n",
    "axins.grid(True)\n",
    "x1, x2, y1, y2 = 0, 20, 50, 2000 # specify the limits\n",
    "axins.set_xlim(x1, x2) # apply the x-limits\n",
    "axins.set_ylim(y1, y2) # apply the y-limits\n",
    "axins.set_xticks(np.arange(0, 20, 5))\n",
    "mark_inset(ax, axins, loc1=2, loc2=3, fc=\"none\", ec=\"0.5\", lw=2)\n",
    "\n",
    "fig.savefig('pca_singular.pdf', dpi=10)\n",
    "\n",
    "# Scatterplot matrix\n",
    "df_pca = pd.DataFrame({**{'cluster': label_pca}, **{col+1: X_pca[:, col] for col in range(2 * d_pca)}})\n",
    "sns.pairplot(df_pca, hue='cluster', vars=np.arange(1, 1 + 2 * d_pca))\n",
    "plt.savefig('pca_scatter.pdf', dpi=10)\n",
    "\n",
    "# Gap statistics\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "ax.errorbar(k_range, np.mean(gap_pca, axis=0), yerr=np.std(gap_pca, axis=0))\n",
    "ax.grid(True)\n",
    "ax.set_xlabel('$k$', **axis_font)\n",
    "ax.set_ylabel('Gap', **axis_font)\n",
    "fig.savefig('pca_gap.pdf', dpi=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 2: Dimension reduction by diffusion maps and/or spectral clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_dif = 3 # For PCA we reduce the dimension of X down to 3 for 3-D visualization\n",
    "k_dif = 2 # The expected number of clusters for diffusion map\n",
    "t_dif = 20 # The time scale for diffusion map\n",
    "f = 10 # The factor used to set epsilon according to the median of the square pairwise Euclidean distance\n",
    "\n",
    "distance = pdist(np.concatenate((X.real, X.imag), axis=1), 'euclidean');\n",
    "epsilon = np.median(distance ** 2) / f;\n",
    "W = np.exp(-squareform(distance) ** 2 / epsilon)\n",
    "D_inv_sqrt = np.diag(1 / np.sqrt(np.sum(W, axis=1)))\n",
    "MS = np.dot(np.dot(D_inv_sqrt, W), D_inv_sqrt) # The symmetric M matrix\n",
    "\n",
    "l_dif, V_dif = eigh(MS, eigvals=(n-d_dif-1, n-2)) # Remember to ignore the largest eigen vector\n",
    "l_dif, V_dif = l_dif[::-1], V_dif[:, ::-1] # The eigen value are now in descending order. \n",
    "\n",
    "X_dif = np.dot(np.dot(D_inv_sqrt, V_dif), np.diag(l_dif ** t_dif)) # The redued dimension map at time t\n",
    "\n",
    "label_dif = KMeans(n_clusters=k_dif, random_state=random_state).fit_predict(X_dif)\n",
    "gap_dif = get_gapstat(X_dif, k_range=k_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scattermatrix plot, the 3-D scatter plot of the reduced-dimension data and the Gap statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_dif = pd.DataFrame({**{'cluster': label_dif}, **{col+1: X_dif[:, col] for col in range(d_dif)}})\n",
    "plot_scatterplot = sns.pairplot(df_dif, hue='cluster', vars=np.arange(1, 1 + d_dif))\n",
    "plt.savefig('dif_scatter.pdf', dpi=10)\n",
    "\n",
    "fig = plt.figure(1, figsize=(7, 6))\n",
    "plt.clf()\n",
    "ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n",
    "plt.cla()\n",
    "\n",
    "y = np.choose(label_dif, ['b', 'g'])\n",
    "ax.scatter(X_dif[:, 0], X_dif[:, 1], X_dif[:, 2], c=y)\n",
    "ax.set_xlabel('1', **axis_font)\n",
    "ax.set_ylabel('2', **axis_font)\n",
    "ax.set_zlabel('3', **axis_font)\n",
    "fig.savefig('dif_3d.pdf', dpi=10)\n",
    "\n",
    "# Gap statistics\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "ax.errorbar(k_range, np.mean(gap_dif, axis=0), yerr=np.std(gap_dif, axis=0))\n",
    "ax.grid(True)\n",
    "ax.set_xlabel('$k$', **axis_font)\n",
    "ax.set_ylabel('Gap', **axis_font)\n",
    "\n",
    "fig.savefig('dif_gap.pdf', dpi=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spectral clustering method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k_spec = 5 # The expected number of clusters for spectral clustering\n",
    "\n",
    "L = np.diag(sum(W)) - W\n",
    "_, V_spec = eigh(L)\n",
    "X_spec = V_spec[:, 1:2] # The reduced dimension data, simply the second smallest eigen vector of L\n",
    "label_spec = KMeans(n_clusters=k_spec, random_state=random_state).fit_predict(X_spec)\n",
    "gap_spec = get_gapstat(X_spec, k_range=k_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram of the second smallest eigen vector of $L$ and the Gap statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "\n",
    "c = ['b', 'g', 'r', 'purple', 'orange']\n",
    "for k in range(k_spec):\n",
    "    ax.hist(X_spec[label_spec==k, 0], 20, facecolor=c[k], alpha=0.75, label='cluster {0}'.format(k))\n",
    "ax.legend(loc=1, fontsize=16)\n",
    "ax.set_xlabel('$v$', **axis_font)\n",
    "ax.set_ylabel('count', **axis_font)\n",
    "fig.savefig('spec_hist.pdf', dpi=10)\n",
    "\n",
    "# Gap statistics\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "ax.errorbar(k_range, np.mean(gap_spec, axis=0), yerr=np.std(gap_spec, axis=0))\n",
    "ax.grid(True)\n",
    "ax.set_xlabel('$k$', **axis_font)\n",
    "ax.set_ylabel('Gap', **axis_font)\n",
    "fig.savefig('spec_gap.pdf', dpi=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
