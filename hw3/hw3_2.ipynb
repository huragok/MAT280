{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import cmath\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.linalg import svd\n",
    "from scipy import io\n",
    "from scipy.linalg import eigh\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from mpl_toolkits.axes_grid1.inset_locator import mark_inset\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib qt\n",
    "axis_font = {'size':'16'}\n",
    "mpl.rcParams['xtick.labelsize'] = 16\n",
    "mpl.rcParams['ytick.labelsize'] = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data files. The 8 non-empty strings are mapped to the unit circle in the complex plane separated by 45 degrees and '--' are mapped to the origin. In this way we hope that the 'pure' patters are separated by the 'hybrid' patters, and '--' is not biased towards any non-empty pattern. Each column of $X$ are shifted to have zero mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = io.loadmat('genomedata.mat')\n",
    "map_gen = {'AA': complex(0.0, 1.0),\n",
    "           'CC': complex(-1.0, 0.0),\n",
    "           'GG': complex(1.0, 0.0),\n",
    "           'TT': complex(0.0, -1.0),\n",
    "           'AG': complex(1.0 / math.sqrt(2), 1.0 / math.sqrt(2)),\n",
    "           'AC': complex(-1.0 / math.sqrt(2), 1.0 / math.sqrt(2)),\n",
    "           'TC': complex(-1.0 / math.sqrt(2), -1.0 / math.sqrt(2)),\n",
    "           'TG': complex(1.0 / math.sqrt(2), -1.0 / math.sqrt(2)), \n",
    "           '--': complex(0.0, 0.0)}\n",
    "\n",
    "X_raw = [[string.strip() for string in row[0][0].strip().split('\\t')] for row in data['X']]\n",
    "X = np.array([[map_gen[string] for string in row] for row in X_raw])\n",
    "n, p = X.shape\n",
    "X = X - np.mean(X, axis=0) * np.ones(p)\n",
    "\n",
    "random_state = 8 # The random state used by the KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 1: Dimension reduction by PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_pca = 2 # For PCA we reduce the dimension of X down to 3\n",
    "k_pca = 2 # The expected number of clusters for PCA\n",
    "\n",
    "_, s_pca, V_pca = svd(X) # svd of X. Note that this is different from matlab in that X = U diag(s) V.\n",
    "V_pca = np.conjugate(V_pca.T)\n",
    "\n",
    "X_pca_complex = np.dot(X, V_pca[:, 0 : d_pca]) # Reduce the dimension of X by linear projection, a complex matrix\n",
    "\n",
    "# Since KMeans does not seem to support complex value, expand the space to 2*d_pca dim\n",
    "X_pca = np.empty((n, 2 * d_pca), dtype=\"float64\") \n",
    "X_pca[:, 0::2] = X_pca_complex.real\n",
    "X_pca[:, 1::2] = X_pca_complex.imag\n",
    "\n",
    "label_pca = KMeans(n_clusters=k_pca, random_state=random_state).fit_predict(X_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the distribution of the singular value and the scattermatrix plot of the reduced dimension data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.PairGrid at 0x7fe163866da0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "axins = inset_axes(ax, 2, 3, loc=1) # zoom-factor: 2.5, location: upper-left\n",
    "\n",
    "ax.semilogy(np.arange(p), s_pca, linewidth=2)\n",
    "ax.grid(True)\n",
    "ax.set_xlabel('dimension', **axis_font)\n",
    "ax.set_ylabel('singular value', **axis_font)\n",
    "\n",
    "axins.semilogy(np.arange(p), s_pca, linewidth=2)\n",
    "axins.grid(True)\n",
    "x1, x2, y1, y2 = 0, 20, 50, 2000 # specify the limits\n",
    "axins.set_xlim(x1, x2) # apply the x-limits\n",
    "axins.set_ylim(y1, y2) # apply the y-limits\n",
    "axins.set_xticks(np.arange(0, 20, 5))\n",
    "mark_inset(ax, axins, loc1=2, loc2=3, fc=\"none\", ec=\"0.5\", lw=2)\n",
    "\n",
    "# Scatterplot matrix\n",
    "df_pca = pd.DataFrame({**{'cluster': label_pca}, **{col+1: X_pca[:, col] for col in range(2 * d_pca)}})\n",
    "sns.set()\n",
    "sns.pairplot(df_pca, hue='cluster', vars=np.arange(1, 1 + 2 * d_pca))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 2: Dimension reduction by diffusion maps and/or spectral clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_dif = 3 # For PCA we reduce the dimension of X down to 3 for 3-D visualization\n",
    "k_dif = 2 # The expected number of clusters for diffusion map\n",
    "t_dif = 10 # The time scale for diffusion map\n",
    "f = 10 # The factor used to set epsilon according to the median of the square pairwise Euclidean distance\n",
    "\n",
    "distance = pdist(np.concatenate((X.real, X.imag), axis=1), 'euclidean');\n",
    "epsilon = np.median(distance ** 2) / f;\n",
    "W = np.exp(-squareform(distance) ** 2 / epsilon)\n",
    "D_inv_sqrt = np.diag(1 / np.sqrt(np.sum(W, axis=1)))\n",
    "MS = np.dot(np.dot(D_inv_sqrt, W), D_inv_sqrt) # The symmetric M matrix\n",
    "\n",
    "l_dif, V_dif = eigh(MS, eigvals=(n-d_dif-1, n-2)) # Remember to ignore the largest eigen vector\n",
    "l_dif, V_dif = l_dif[::-1], V_dif[:, ::-1] # The eigen value are now in descending order. \n",
    "\n",
    "X_dif = np.dot(np.dot(D_inv_sqrt, V_dif), np.diag(l_dif ** t_dif)) # The redued dimension map at time t\n",
    "\n",
    "label_dif = KMeans(n_clusters=k_dif, random_state=random_state).fit_predict(X_dif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scattermatrix plot and the 3-D scatter plot of the reduced-dimension data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7fe159e168d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dif = pd.DataFrame({**{'cluster': label_dif}, **{col+1: X_dif[:, col] for col in range(d_dif)}})\n",
    "plot_scatterplot = sns.pairplot(df_dif, hue='cluster', vars=np.arange(1, 1 + d_dif))\n",
    "\n",
    "fig = plt.figure(1, figsize=(7, 6))\n",
    "plt.clf()\n",
    "ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n",
    "plt.cla()\n",
    "\n",
    "y = np.choose(label_dif, ['b', 'g'])\n",
    "ax.scatter(X_dif[:, 0], X_dif[:, 1], X_dif[:, 2], c=y)\n",
    "ax.set_xlabel('1', **axis_font)\n",
    "ax.set_ylabel('2', **axis_font)\n",
    "ax.set_zlabel('3', **axis_font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spectral clustering method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k_spec = 2 # The expected number of clusters for spectral clustering\n",
    "\n",
    "L = np.diag(sum(W)) - W\n",
    "_, V_spec = eigh(L)\n",
    "X_spec = V_spec[:, 1:2] # The reduced dimension data, simply the second smallest eigen vector of L\n",
    "label_spec = KMeans(n_clusters=2, random_state=random_state).fit_predict(X_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram of the second smallest eigen vector of $L$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7fe15a0f09b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "ax.hist(X_spec[label_spec==0, 0], 20, normed=1, facecolor='blue', alpha=0.75, label='cluster 0')\n",
    "ax.hist(X_spec[label_spec==1, 0], 20, normed=1, facecolor='green', alpha=0.75, label='cluster 1')\n",
    "ax.legend(loc=1, fontsize=16)\n",
    "ax.set_xlabel('$v$', **axis_font)\n",
    "ax.set_ylabel('count', **axis_font)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
