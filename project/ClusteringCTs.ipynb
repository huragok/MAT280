{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas.io.sql as pdsql\n",
    "import pickle\n",
    "\n",
    "import psycopg2\n",
    "\n",
    "from numpy.random import uniform\n",
    "from numpy.linalg import svd\n",
    "from scipy.linalg import eigh\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from shapely.wkt import loads as wkt_loads\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.collections import LineCollection, PatchCollection\n",
    "\n",
    "%matplotlib qt\n",
    "axis_font = {'size':'20'}\n",
    "mpl.rcParams['xtick.labelsize'] = 20\n",
    "mpl.rcParams['ytick.labelsize'] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read the pickup_count table and the day_info table\n",
    "conn = psycopg2.connect(\"dbname='nyc_taxi' user='postgres' host='localhost' password='organon'\")\n",
    "cdf = pdsql.read_sql(\"SELECT * FROM count_by_hour_ct\", conn, params=None)\n",
    "#cdf = pdsql.read_sql(\"SELECT * FROM count_by_hour_ct_green\", conn, params=None)\n",
    "ct = pdsql.read_sql(\"SELECT gid, boro_name, shape_area, boro_ct201, ntaname FROM ct\", conn, coerce_float=True, params=None)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove the NaN entries\n",
    "idx_nan_pickup = np.where(pd.isnull(cdf['pickup_gid']).values)[0].tolist()\n",
    "idx_nan_dropoff = np.where(pd.isnull(cdf['dropoff_gid']).values)[0].tolist()\n",
    "\n",
    "row = 0\n",
    "for row in range(len(cdf.index)):\n",
    "    if row in idx_nan_pickup:\n",
    "        cdf.set_value(row, 'pickup_gid', cdf['dropoff_gid'][row])\n",
    "        cdf.set_value(row, 'pickup_hour', cdf['dropoff_hour'][row])\n",
    "        cdf.set_value(row, 'count_mean_pickup', 0.0)   \n",
    "        \n",
    "    if row in idx_nan_dropoff:\n",
    "        cdf.set_value(row, 'dropoff_gid', cdf['pickup_gid'][row])\n",
    "        cdf.set_value(row, 'dropoff_hour', cdf['pickup_hour'][row])\n",
    "        cdf.set_value(row, 'count_mean_dropoff', 0.0)   \n",
    "        \n",
    "cdf['pickup_gid'] = cdf['pickup_gid'].astype(int)\n",
    "cdf['pickup_hour'] = cdf['pickup_hour'].astype(int)\n",
    "cdf['dropoff_gid'] = cdf['dropoff_gid'].astype(int)\n",
    "cdf['dropoff_hour'] = cdf['dropoff_hour'].astype(int)   \n",
    "\n",
    "# Construct the numpy array where each row corresponds to the average number of pickups in the 24 hours of a \n",
    "# day + number of dropoffs in the 24 hours of a averaged over 1 year\n",
    "X = np.zeros((2166, 48), dtype='float64')\n",
    "\n",
    "for row in range(len(cdf.index)):\n",
    "    X[(cdf.pickup_gid[row]-1)][cdf.pickup_hour[row]] = cdf.count_mean_pickup[row]\n",
    "    X[(cdf.pickup_gid[row]-1)][cdf.pickup_hour[row]+24] = cdf.count_mean_dropoff[row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Study only the census tracts where there are enough pickup and dropoffs per day\n",
    "min_daily_count = 4500\n",
    "#min_daily_count = 300\n",
    "gids_popular = np.where(np.sum(X, axis=1) > min_daily_count)[0] + 1\n",
    "\n",
    "X_popular = X[gids_popular-1, :]\n",
    "Y = np.dot(np.diag(1 / np.sum(X_popular, axis=1)), X_popular) # Normalize each row of X_popular\n",
    "\n",
    "[np.sum(label==k) for k in range(K)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Spectral clustering to cluster the hourly pickup-dropoff patterns for all 2166 census tracks\n",
    "f =180 # The factor used to set epsilon according to the median of the square pairwise Euclidean distance\n",
    "#f = 160\n",
    "\n",
    "distance = pdist(Y, 'euclidean');\n",
    "epsilon = np.median(distance ** 2) / f;\n",
    "W = np.exp(-squareform(distance) ** 2 / epsilon) # The adjacency matrix\n",
    "\n",
    "# Spectral clustering\n",
    "K = 2\n",
    "L = np.diag(sum(W)) - W\n",
    "_, V_spec = eigh(L)\n",
    "v = V_spec[:, 1:2] # The reduced dimension data, simply the second smallest eigen vector of L\n",
    "label = KMeans(n_clusters=K, random_state=8).fit_predict(v)\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "c = ['b', 'g', 'r', 'purple', 'yellow', 'magenta', 'cyan', 'black', 'white']\n",
    "for k in range(K):\n",
    "    ax.hist(v[label==k, 0], 20, facecolor=c[k], alpha=1, label='cluster {0}'.format(k))\n",
    "ax.legend(loc=1, fontsize=20)\n",
    "ax.grid(True)\n",
    "ax.set_xlabel('$v$', **axis_font)\n",
    "ax.set_ylabel('count', **axis_font)\n",
    "\n",
    "fig.savefig('./figures/clustering/hist_yellow.jpg', dpi=100, bbox_inches='tight')\n",
    "#fig.savefig('./figures/clustering/hist_green.jpg', dpi=100, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The function to evaluate the gap statistic for k-means with different number of clusters\n",
    "def get_gapstat(X, k_range=np.arange(1, 9), n_sample=20, random_state=17):\n",
    "    n, p = X.shape\n",
    "    \n",
    "    X_ref = np.empty((n, p, n_sample), dtype='float64')\n",
    "    for col in range(p):\n",
    "        X_ref[:, col, :] = uniform(low=X[:, col].min(), high=X[:, col].max(), size=(n, n_sample))\n",
    "    \n",
    "    gapstat = np.empty((n_sample, len(k_range)), dtype='float64')\n",
    "    for i_k, k in enumerate(k_range):\n",
    "        km = KMeans(n_clusters=k, random_state=random_state)\n",
    "        \n",
    "        # The inertia of the actual data\n",
    "        km.fit(X)\n",
    "        w = km.inertia_\n",
    "        \n",
    "        # The inertia of the reference data\n",
    "        w_ref = np.empty(n_sample, dtype='float64')\n",
    "        for i_sample in range(n_sample):\n",
    "            km.fit(X_ref[:, :, i_sample])\n",
    "            w_ref[i_sample] = km.inertia_\n",
    "        \n",
    "        gapstat[:, i_k] = np.log(w_ref) - np.log(w)\n",
    "        \n",
    "    return gapstat\n",
    "\n",
    "k_range = np.arange(1, 20)\n",
    "n_sample = 20\n",
    "\n",
    "gap_spec = get_gapstat(v, k_range=k_range, n_sample=n_sample)\n",
    "\n",
    "# Plot the Gap statistics curve\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "ax.errorbar(k_range, np.mean(gap_spec, axis=0), yerr=np.sqrt(1+1/n_sample)*np.std(gap_spec, axis=0))\n",
    "ax.grid(True)\n",
    "ax.set_xlabel('$k$', **axis_font)\n",
    "ax.set_ylabel('Gap', **axis_font)\n",
    "\n",
    "fig.savefig('./figures/clustering/gap_yellow.jpg', dpi=100, bbox_inches='tight')\n",
    "#fig.savefig('./figures/clustering/gap_green.jpg', dpi=100, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "west, south, east, north = -74.15, 40.50, -73.65, 40.95 # New York\n",
    "west, south, east, north = -74.03, 40.7, -73.93, 40.8 # Manhattan\n",
    "\n",
    "n_ct_popular = gids_popular.shape[0]\n",
    "ct_color = {gids_popular[i]: c[label[i]] for i in range(n_ct_popular)} # The color of each census tract\n",
    "ct2gid = {ct.boro_ct201[i]: ct.gid[i] for i in range(len(ct.gid))}\n",
    "\n",
    "# Plot the CT boundaries\n",
    "m = Basemap(llcrnrlon=west, llcrnrlat=south, urcrnrlon=east, urcrnrlat=north,\n",
    "                 resolution='i', projection='merc', lat_0=(south+north)/2, lon_0=(west+east)/2)\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "m.readshapefile('./datasets/ct_2010/geo_export_670644cc-4c81-49e9-9d6d-fb574f649fff', 'nyc', linewidth=2, zorder=1)\n",
    "\n",
    "# Plot the coloring for each cluster\n",
    "patches = []\n",
    "for info, shape in zip(m.nyc_info, m.nyc):\n",
    "    gid = ct2gid[info['boro_ct201']]\n",
    "    if gid in gids_popular:\n",
    "        patches.append(Polygon(np.array(shape), True, facecolor=ct_color[gid]))\n",
    "        p = PatchCollection(patches, match_original=True, alpha=0.6, linewidths=1, zorder=2)\n",
    "\n",
    "ax.add_collection(p)\n",
    "\n",
    "# Plot the scatterplot of the top 20 most reviewed lounges, dance clubs and formal retaurants\n",
    "conn = psycopg2.connect(\"dbname='nyc_taxi' user='postgres' host='localhost' password='organon'\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"\"\"SELECT ST_X(lonlat), ST_Y(lonlat) from hotspot WHERE tag='bars' or tag='lounges'\"\"\")\n",
    "lonlat = np.array(cur.fetchall())\n",
    "x, y = m(lonlat[:, 0], lonlat[:, 1])\n",
    "m.scatter(x, y, s=80, facecolor='r', lw = 1, zorder=3, label='bars/lounges')\n",
    "\n",
    "cur.execute(\"\"\"SELECT ST_X(lonlat), ST_Y(lonlat) from hotspot WHERE tag='dance clubs'\"\"\")\n",
    "lonlat = np.array(cur.fetchall())\n",
    "x, y = m(lonlat[:, 0], lonlat[:, 1])\n",
    "m.scatter(x, y, s=80, facecolor='orange', lw = 1, zorder=3, label='dance clubs')\n",
    "\n",
    "cur.execute(\"\"\"SELECT ST_X(lonlat), ST_Y(lonlat) from hotspot WHERE tag='formals'\"\"\")\n",
    "lonlat = np.array(cur.fetchall())\n",
    "x, y = m(lonlat[:, 0], lonlat[:, 1])\n",
    "m.scatter(x, y, s=80, facecolor='m', lw = 1, zorder=3, label='formal restaurants')\n",
    "\n",
    "ax.legend(loc=1, fontsize=20)\n",
    "\n",
    "conn.close()\n",
    "fig.savefig('./figures/clustering/coloring_yellow_tagged.jpg', dpi=100, bbox_inches='tight')\n",
    "#fig.savefig('./figures/clustering/coloring_green_tagged.jpg', dpi=100, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the daily pickup/dropoff pattern for each cluster\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "t = np.arange(24, dtype='int32')\n",
    "for k in range(K):\n",
    "    Y_subset = Y[label==k, :]\n",
    "    pickup_mean, dropoff_mean = np.mean(Y_subset, axis=0)[0:24], np.mean(Y_subset, axis=0)[24:48]\n",
    "    pickup_std, dropoff_std = np.std(Y_subset, axis=0)[0:24], np.std(Y_subset, axis=0)[24:48]\n",
    "    \n",
    "    ax.plot(t, pickup_mean, color=c[k], linewidth=2, label=\"pickup, $k={0}$\".format(k))\n",
    "    ax.plot(t, -dropoff_mean, color=c[k], linewidth=2, linestyle='--', label=\"-dropoff, $k={0}$\".format(k))\n",
    "    \n",
    "    ax.fill_between(t, pickup_mean-pickup_std, pickup_mean+pickup_std, facecolor=c[k], alpha=0.3)\n",
    "    ax.fill_between(t, -dropoff_mean-dropoff_std, -dropoff_mean+dropoff_std, facecolor=c[k], alpha=0.3)\n",
    "    \n",
    "ax.legend(prop={'size':16}, loc=0)\n",
    "ax.grid()\n",
    "ax.set_xlabel('hour', **axis_font)\n",
    "ax.set_xlim([0, 23])\n",
    "ax.set_ylabel('pickup-dropoff dstr.', **axis_font)\n",
    "\n",
    "fig.savefig('./figures/clustering/curve_yellow.jpg', dpi=100, bbox_inches='tight')\n",
    "#fig.savefig('./figures/clustering/curve_green.jpg', dpi=100, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
